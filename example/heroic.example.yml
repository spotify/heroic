# vim: filetype=yaml
port: 8080

# Schedule for refreshing cluster metadata.
refreshClusterSchedule: "0 */1 * * * ?"

# Cluster configuration.
cluster:
  # Local ID.
  # @default Generated UUID.
  #id: 88b3f090-49f8-43fe-b30e-5ce0e3889884
  # When communicating with self, avoid using the network.
  # @default false
  #useLocal: false
  # Node capabilities.
  #  * QUERY Node can be queried for data (api node).
  #  * WRITE Node can be written to.
  # @default ["QUERY", "WRITE"]
  capabilities:
    - QUERY
  # Discovery mechanism
  discovery:
    ## Static discovery mechanism.
    type: static
    nodes:
      - native://localhost:8100
  # RPC mechanism
  rpc:
    type: native
    host: 0.0.0.0
    port: 8100
    parentThreads: 2
    childThreads: 10

# Metrics configuration.
metrics:
  backends:
    ## Cassandra 2 backend.
    #- type: cassandra2
    #  # Unique id for this backend.
    #  # @default Generated.
    #  #id: null
    #  # Backend group name.
    #  # @default "heroic"
    #  #group: heroic
    #  # Keyspace.
    #  # @default "heroic"
    #  #keyspace: heroic
    #  # Seeds.
    #  # @default empty
    #  #seeds:
    #  #  - localhost
    #  # Max number of connections per host in cluster.
    #  #maxConnectionsPerHost: 50
    ## Generated (infinite) metrics.
    # The generator is consistent so the same queried time series will always
    # result in the same generated values (given the same configuration here!).
    - type: generated
      generator:
        ## Generate a consistent random time series.
        type: random
        # Minimum y-position.
        # @default -100
        #min: -100
        # Maximum y-position.
        # @default 1000
        #max: 1000
        # Step between each data point in milliseconds.
        # @default 10 seconds (in milliseconds)
        #step: 10000
        # Range around y-position that a value can be randomly generated.
        # @default 50
        #range: 50
        ## Generate a consistent sine curve time series.
        #type: sine
        # Absolute peak value.
        # @default 1000
        #magnitude: 1000d
        # How long time in milliseconds for a complete sine curve.
        # @default One day (in milliseconds).
        #period: 86400000

# Metadata backend configuration.
metadata:
  backends:
    ## Lucene metadata.
    - type: lucene
      seed:
        ## Randomly generated metadata.
        type: random
        # Random seed, set if you want consistency.
        # @default Randomly generated.
        seed: 0
    ## ElasticSearch-based metadata.
    #- type: elasticsearch
    #  # Backend id, if not specified it will be generated.
    #  # @default null
    #  #id: null
    #  # Name of elasticsearch cluster.
    #  # @default "elasticsearch"
    #  #clusterName: elasticsearch
    #  # ElasticSearch index.
    #  # @default "heroic"
    #  #index:
    #  # Index mapping to use
    #  # @default Single
    #  #  #type: single
    #  #  # Single index type that only operates on a single index.
    #  #  #index: heroic
    #  #  # Rotating index type that creates new indices over time.
    #  #  #type: rotating
    #  #  # Pattern to use when creating index.
    #  #  # The pattern must contain a single '%s' that will be
    #  #  # replaced with the base time stamp of the index.
    #  #  # @default "heroic-%s"
    #  #  #pattern: heroic-%s
    #  #  # Interval in milliseconds that each index is valid.
    #  #  # @default: 604800000 (one week)
    #  #  #interval: 604800000
    #  # Use node client transport.
    #  # If true, heroic will join ElasticSearch as a read-only node.
    #  # @default false
    #  #nodeClient: false
    #  # How many buffered write actions are allowed.
    #  # @default 1000
    #  #writeBulkActions: 1000
    #  # Bulk dump interval in seconds.
    #  # @default 1
    #  #dumpInterval: 1
    #  # How many requests are sent to the server in bulk.
    #  # @default 5
    #  #concurrentBulkRequests: 5
    #  #Seed nodes (required).
    #  seeds:
    #    - localhost:9200

# Data consumers.
#consumers:
#  - type: kafka
#    # Id for consumer.
#    # @default Generated
#    #id: null
#    # Topics to consume from (required).
#    topics:
#      - "metrics"
#    # Schema to use when consuming (required).
#    # The fully qualified class name of a schema implementation for consuming.
#    #schema: com.spotify.heroic.consumer.schemas.Spotify100
#    # Threads per topic.
#    # @default 2
#    #threadsPerTopic: 2
#    # Kafka configuration.
#    # The provided map will be passed in directly as the kafka configuration.
#    # For available configuration options, see:
#    #   https://kafka.apache.org/08/configuration.html#consumerconfigs
#    #config:
#    #  zookeeper.connect: localhost:2181
#    #  group.id: heroic
#  - type: pubsub
#    # Id for consumer
#    # @default Generated
#    id: null
#    # Topic to consume from (required.) Will be created if it doesn't exist.
#    topic: metrics
#    # GCP project to consume from (required.)
#    project: heroic
#    # Subscription name to consume from (required.) Will be created if it doesn't exist.
#    subscription: heroic-consumer
#    # Schema to use when consuming (required).
#    # The fully qualified class name of a schema implementation for consuming.
#    #schema: com.spotify.heroic.consumer.schemas.Spotify100
#    # Threads per topic.
#    # @default 8
#    #threadsPerTopic: 2
#    # Maximum number of messages the consumer can have unacked.
#    # @default 10000
#    #maxOutStandingElementCount: 50000
#    # Maximum byte size of messages the consumer can have unacked.
#    # @default 1000000000
#    #maxOutstandingRequestBytes: 2000000000
#    # Maxiumum size of a single incoming message, in bytes. 20MB is the highest allowed by the API.
#    # @default 20971520
#    #maxInboundMessageSize: 40960000
#    # Amount of time to keep the PubSub connection alive, in seconds.
#    # @default 300
#    #keepAlive: 600

## Aggregation cache.
#cache:
#  backend:
#    ## In-memory based aggregation cache.
#    #type: memory
#    ## Cassandra based cache.
#    #type: cassandra2
#    #  # Keyspace.
#    #  # @default "heroic"
#    #  #keyspace: heroic
#    #  # Seeds.
#    #  # @default empty
#    #  #seeds:
#    #  #  - localhost
#    #  # Max number of connections per host in cluster.
#    #  #maxConnectionsPerHost: 50

## Http client configuration.
#client:
#  # Number of threads to use for client requests.
#  # @default 100
#  #threads: 100
#  # Max amounts of pending requests, if all client threads are occupied.
#  # @default 100
#  #queueSize: 100
#  # Timeout in milliseconds for establishing a client connection.
#  # @default 2000
#  #connectTimeout: 2000
#  # Timeout in milliseconds for reading from a server.
#  # @default 120000
#  #readTimeout: 120000

## Detailed Query Logging
#queryLogging:
#  type: slf4j

## Tracing configuration
#tracing:
#  # Probability, between 0.0 and 1.0, of sampling each trace.
#  # @default 0.01
#  #probability: 0.01
#  # Local port to expose zpages on. Traces are accessible at http://localhost:{port}/tracez
#  # @default empty
#  #zpagesPort: 9090
#  #lightstep:
#  #  # Collector host running the satellite (required)
#  #  collectorHost: "lightstep-satellite.services.heroic"
#  #  # Lightstep access token (required)
#  #  accessToken: "lightstep_token"
#  #  # Reporting interval (ms)
#  #  # @default 1000
#  #  reportingIntervalMs: 1_000
#  #  # Max buffered spans
#  #  # @default 1000
#  #  maxBufferedSpans: 1_000
#  #  GRPC round robin
#  #  # @default true
#  #  #grpcRoundRobin: true
#  #  GRPC reset client
#  #  # @default false
#  #  #grpcResetClient: false
#  #  GRPC Collector Target (required)
#  #  #grpcCollectorTarget: "dns:///foo.googleapis:8282"
